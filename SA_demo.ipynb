{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "jewish-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-fighter",
   "metadata": {},
   "source": [
    "Dataset: https://www.kaggle.com/kazanova/sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "editorial-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\", header=None)\n",
    "df.columns = ['target', 'id', 'date', 'flag', 'user', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eleven-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select equal number of positives and negatives\n",
    "SIZE = 100_000\n",
    "HALF = df.shape[0]//2\n",
    "df = df[HALF-SIZE//2 : HALF + SIZE//2]\n",
    "df = df[['target', 'text']]\n",
    "\n",
    "# Convert 4 (positive sentiment) to 1\n",
    "df['target'].loc[df['target']==4]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "delayed-movie",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50000\n",
       "1    50000\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-display",
   "metadata": {},
   "source": [
    "#### Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-dealer",
   "metadata": {},
   "source": [
    "From: https://github.com/francisbautista/cs174/blob/master/Notebooks/L04%20-%20Word2Vec.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hearing-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "def preprocess(text):\n",
    "    text=text.lower()\n",
    "    text=re.sub('[^0-9a-z]+',' ',text)\n",
    "    split = text.split()\n",
    "    stopped = [i for i in split if i not in stop]\n",
    "    return(stopped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "novel-diamond",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-yellow",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Find word embeddings with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "central-february",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(vector_size=100,window=5,min_count=30, sg=0, alpha = 0.025)\n",
    "model.build_vocab(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "wrapped-description",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10628337, 15747320)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(df['text'], total_examples=model.corpus_count, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "foreign-statistics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.8401327 , -0.12655145, -0.2615346 , -0.08966108, -0.2411643 ,\n",
       "        0.17588767, -0.05176534, -0.77485263, -0.9294774 , -0.04847171,\n",
       "       -1.0483187 ,  0.03595317,  0.6951262 ,  0.71502125, -0.80962217,\n",
       "        1.4862753 , -1.1999292 , -1.9038987 ,  1.0247109 , -0.7031982 ,\n",
       "       -0.3057754 ,  1.122382  ,  0.04555465,  0.4490463 ,  0.5786158 ,\n",
       "       -0.18380849, -0.5258619 , -0.50375044, -0.5838184 , -1.2942679 ,\n",
       "        1.7767905 , -0.10134457, -0.18711028,  0.5720447 ,  1.6598778 ,\n",
       "       -0.4235221 ,  0.18281151, -1.0474579 ,  1.0910946 ,  0.9474104 ,\n",
       "        0.26177794, -0.87623984, -0.64355826,  0.4212355 , -1.2992284 ,\n",
       "       -1.9732645 ,  1.4332736 ,  0.97949386,  1.228907  ,  0.39390478,\n",
       "       -0.03572264,  0.28478923,  0.3840845 ,  0.8590543 ,  0.15114051,\n",
       "        2.1014726 ,  1.9921099 , -1.7943714 , -0.15593657,  1.31003   ,\n",
       "        0.13420065,  0.44884428, -1.4568623 , -0.44079947, -1.4011059 ,\n",
       "        0.8235898 ,  1.575923  , -1.8408499 ,  1.3058144 , -0.12796906,\n",
       "        0.94104594,  1.0783184 , -0.30371875,  0.71842754, -0.89534414,\n",
       "        0.03508623,  0.1623079 , -0.8382507 ,  1.2799007 ,  0.5085293 ,\n",
       "       -0.91920847,  0.5108806 , -1.0893086 , -0.10772899,  0.45575255,\n",
       "        0.40570885,  0.5106269 , -0.0129765 ,  0.8437821 ,  0.26684675,\n",
       "        0.3142549 ,  1.2900735 ,  1.1377013 , -1.0074033 , -0.21066742,\n",
       "        0.33741865,  0.01778448,  0.68286806,  1.4027995 , -0.60058016],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "indian-syracuse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('exam', 0.7302709817886353),\n",
       " ('math', 0.6260785460472107),\n",
       " ('maths', 0.5837710499763489),\n",
       " ('essay', 0.5488294363021851),\n",
       " ('tests', 0.5474931001663208),\n",
       " ('study', 0.517629861831665),\n",
       " ('lesson', 0.49804648756980896),\n",
       " ('classes', 0.48566314578056335),\n",
       " ('results', 0.4845176339149475),\n",
       " ('report', 0.47734901309013367)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-compatibility",
   "metadata": {},
   "source": [
    "#### Get avg. vector for each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "contemporary-longer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x106798dc0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "portuguese-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_vec(list_of_words, model=None):\n",
    "    vec = np.zeros(model.wv.vector_size)\n",
    "    for word in list_of_words:\n",
    "        try:\n",
    "            vec += model.wv[word]\n",
    "        except:\n",
    "            pass\n",
    "    vec = vec / np.sqrt(vec @ vec)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "pressing-infection",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_vec'] = df['text'].apply(get_avg_vec, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "occasional-missouri",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>avg_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[opotopo, small, slip, tryfan, weeks, back, fe...</td>\n",
       "      <td>[0.016425926464839584, 0.12428556633569253, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[idristwilight, post, han, want, great, still,...</td>\n",
       "      <td>[-0.026964444126323477, 0.18897072704175477, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[rose, 7, ohh, poor, jan, please, tell, cans, ...</td>\n",
       "      <td>[0.07908398287381788, 0.14591578719337936, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[finally, home, work, looong, day, monday]</td>\n",
       "      <td>[0.08054435665207227, 0.10106137663281431, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[im, sad, 4, chantelle, tom]</td>\n",
       "      <td>[0.07889970227565675, 0.03331143744581845, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>1</td>\n",
       "      <td>[need, 8, followers, compleate, 1000, follow, ...</td>\n",
       "      <td>[-0.10657259495495827, -0.024300254978452996, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>1</td>\n",
       "      <td>[knew, explain, something, friend, said, star,...</td>\n",
       "      <td>[0.03454132665704356, 0.09592750909769618, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>1</td>\n",
       "      <td>[done, tweeting, til, tomorrow]</td>\n",
       "      <td>[0.06679701033272802, -0.011243648040071, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>1</td>\n",
       "      <td>[cmozilo, act, ii, set, pretty, breath, taking...</td>\n",
       "      <td>[0.1404100067437189, 0.1036930500500789, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>1</td>\n",
       "      <td>[artfire, account, sell, fun, things, suggest,...</td>\n",
       "      <td>[0.02683272121562202, -0.016287156509741198, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target                                               text  \\\n",
       "0           0  [opotopo, small, slip, tryfan, weeks, back, fe...   \n",
       "1           0  [idristwilight, post, han, want, great, still,...   \n",
       "2           0  [rose, 7, ohh, poor, jan, please, tell, cans, ...   \n",
       "3           0         [finally, home, work, looong, day, monday]   \n",
       "4           0                       [im, sad, 4, chantelle, tom]   \n",
       "...       ...                                                ...   \n",
       "99995       1  [need, 8, followers, compleate, 1000, follow, ...   \n",
       "99996       1  [knew, explain, something, friend, said, star,...   \n",
       "99997       1                    [done, tweeting, til, tomorrow]   \n",
       "99998       1  [cmozilo, act, ii, set, pretty, breath, taking...   \n",
       "99999       1  [artfire, account, sell, fun, things, suggest,...   \n",
       "\n",
       "                                                 avg_vec  \n",
       "0      [0.016425926464839584, 0.12428556633569253, 0....  \n",
       "1      [-0.026964444126323477, 0.18897072704175477, -...  \n",
       "2      [0.07908398287381788, 0.14591578719337936, 0.0...  \n",
       "3      [0.08054435665207227, 0.10106137663281431, -0....  \n",
       "4      [0.07889970227565675, 0.03331143744581845, -0....  \n",
       "...                                                  ...  \n",
       "99995  [-0.10657259495495827, -0.024300254978452996, ...  \n",
       "99996  [0.03454132665704356, 0.09592750909769618, -0....  \n",
       "99997  [0.06679701033272802, -0.011243648040071, -0.0...  \n",
       "99998  [0.1404100067437189, 0.1036930500500789, -0.04...  \n",
       "99999  [0.02683272121562202, -0.016287156509741198, -...  \n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-harvard",
   "metadata": {},
   "source": [
    "#### Split into train, test, validation sets\n",
    "\n",
    "* 70% = training\n",
    "* 15% = test\n",
    "* 15% = validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-possibility",
   "metadata": {},
   "source": [
    "Shuffle the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "described-rugby",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffled = df.sample(frac=1)\n",
    "df_shuffled.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "proprietary-spirit",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = df_shuffled.iloc[:70_000]\n",
    "test_set = df_shuffled.iloc[70_000:85_000]\n",
    "val_set = df_shuffled.iloc[85_000:]\n",
    "\n",
    "X_train = train_set['avg_vec'].to_numpy().reshape(-1, 1)\n",
    "y_train = train_set['target'].to_numpy()\n",
    "\n",
    "X_test = test_set['avg_vec'].to_numpy().reshape(-1, 1)\n",
    "y_test = test_set['target']\n",
    "\n",
    "X_val = val_set['avg_vec'].to_numpy().reshape(-1, 1)\n",
    "y_val = val_set['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "pregnant-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate(np.concatenate(X_train, axis=0), axis=0).reshape(-1, 100)\n",
    "X_test = np.concatenate(np.concatenate(X_test, axis=0), axis=0).reshape(-1, 100)\n",
    "X_val = np.concatenate(np.concatenate(X_val, axis=0), axis=0).reshape(-1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "august-satisfaction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "standing-kingdom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-eligibility",
   "metadata": {},
   "source": [
    "#### Classify with RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-video",
   "metadata": {},
   "source": [
    "Remove null and nan values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fiscal-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.nan_to_num(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "qualified-least",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier()\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "wound-terrorism",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: ['never', 'go', 'see', 'movie', 'without', 'first', 'reading', 'matt', 'mungle', 'review', 'transformers']\n",
      "Prediction: 0\n",
      "Actual: 0\n",
      "********************\n",
      "Text: ['woop', '200', 'updates', 'god', 'boring']\n",
      "Prediction: 0\n",
      "Actual: 1\n",
      "********************\n",
      "Text: ['awake', 'neither', 'caffeinated', 'functional', 'yet', 'awake']\n",
      "Prediction: 0\n",
      "Actual: 1\n",
      "********************\n",
      "Text: ['williammm', 'lol', 'know', 'always', 'think', 'go', 'vagina', 'monoglues', 'see', 'chocolates']\n",
      "Prediction: 0\n",
      "Actual: 1\n",
      "********************\n",
      "Text: ['need', 'start', 'take', 'home', 'test']\n",
      "Prediction: 0\n",
      "Actual: 0\n",
      "********************\n",
      "Text: ['cartoonbeardy', 'oooo', 'jammy', 'git', 'ever', 'look', 'forward', 'post', 'tweets']\n",
      "Prediction: 1\n",
      "Actual: 1\n",
      "********************\n",
      "Text: ['hypnoticzexy', 'cut', 'shorter', 'imagined', 'growing', 'getting', 'thick', 'miss', 'already']\n",
      "Prediction: 0\n",
      "Actual: 0\n",
      "********************\n",
      "Text: ['another', 'power', 'day', 'way', 'home']\n",
      "Prediction: 0\n",
      "Actual: 1\n",
      "********************\n",
      "Text: ['finally', 'calm', 'ready', 'bed', 'positive', 'thoughts', 'rest', 'day']\n",
      "Prediction: 1\n",
      "Actual: 1\n",
      "********************\n",
      "Text: ['lots', 'great', 'perezhilton', 'com', 'thesuperficial', 'com', 'catch', 'also', 'j', 'amp', 'k', '8', 'big', 'announcement', 'tonight', 'bet', 'get', 'divorced']\n",
      "Prediction: 1\n",
      "Actual: 0\n",
      "********************\n",
      "Text: ['blackqueen1010', 'ha', 'keep', 'trying', 'set', 'lunch', 'zintaaistars', 'usually', 'end', 'canceling', 'thing', 'called', 'work']\n",
      "Prediction: 1\n",
      "Actual: 0\n",
      "********************\n",
      "Text: ['birthday', 'cake', 'oven', 'fingers', 'crossed', 'looks', 'tastes', 'good']\n",
      "Prediction: 1\n",
      "Actual: 1\n",
      "********************\n",
      "Text: ['never', 'bored', 'online', 'life', 'maanmarquez', 'like', 'saan', 'bored']\n",
      "Prediction: 0\n",
      "Actual: 0\n",
      "********************\n",
      "Text: ['milfordtimes', 'think', 'apple', 'amp', 'like', 'see', 'many', 'hoops', 'make', 'customers', 'jump', 'frustrating', 'sometimes']\n",
      "Prediction: 1\n",
      "Actual: 0\n",
      "********************\n",
      "Text: ['xantha', 'congratulations', 'hope', 'wonderful', 'birthday', 'yesterday']\n",
      "Prediction: 1\n",
      "Actual: 1\n",
      "********************\n",
      "Text: ['watching', 'life', 'ryan']\n",
      "Prediction: 1\n",
      "Actual: 1\n",
      "********************\n",
      "Text: ['tyrese4real', 'yeah', 'lol', 'lot']\n",
      "Prediction: 1\n",
      "Actual: 1\n",
      "********************\n",
      "Text: ['alittletrendy', 'honestly', 'know', 'hybrid', 'cursing', 'fucking', 'crazy', 'cursebird', 'counting', 'things', 'shit']\n",
      "Prediction: 0\n",
      "Actual: 0\n",
      "********************\n",
      "Text: ['christinecx', 'mate', 'good', 'actually', 'annoyed', 'right', 'miss', 'xx']\n",
      "Prediction: 1\n",
      "Actual: 0\n",
      "********************\n",
      "Text: ['ok', 'softball', 'tournament', 'yesterday', 'didnt', 'get', 'home', '1', 'oh', 'clock', 'morning', 'fun']\n",
      "Prediction: 0\n",
      "Actual: 1\n",
      "********************\n",
      "Text: ['formerexaminer', 'drat', 'beat', 'ssi', 'garnishment', 'issue', 'upcoming', 'post', 'great', 'article']\n",
      "Prediction: 1\n",
      "Actual: 1\n",
      "********************\n",
      "Text: ['deru', 'musicyall', 'got', 'fucking', 'problem']\n",
      "Prediction: 0\n",
      "Actual: 1\n",
      "********************\n",
      "Text: ['plans', 'grill', 'outside', 'tonight', 'foiled', 'grill', 'light']\n",
      "Prediction: 0\n",
      "Actual: 0\n",
      "********************\n",
      "Text: ['tweet', 'day', 'lol', 'miss']\n",
      "Prediction: 0\n",
      "Actual: 0\n",
      "********************\n",
      "Text: ['saw', 'hummingbird', 'hit', 'library', 'window', 'moved', 'brush', 'recover', 'safely', 'poor', 'guy', 'http', 'twitpic', 'com', '8dupd']\n",
      "Prediction: 0\n",
      "Actual: 0\n",
      "********************\n",
      "Text: ['tickteevee', 'alright', 'lee', 'yes', 'lee', 'lovely', 'friend', 'ol', 'buddy', 'ol', 'pal', 'slept', 'like', 'baby', 'ty', 'asking', 'beautiful', 'sweet', 'lovey', 'dovey']\n",
      "Prediction: 1\n",
      "Actual: 1\n",
      "********************\n",
      "Text: ['lillyluna', 'died', 'read', 'article', 'day', 'saying', 'going', 'marry', 'guy', 'like', 'ever', 'sad']\n",
      "Prediction: 0\n",
      "Actual: 0\n",
      "********************\n",
      "Text: ['omg', 'bad', 'exams', 'help']\n",
      "Prediction: 0\n",
      "Actual: 0\n",
      "********************\n",
      "Text: ['ate', 'much', 'dinner']\n",
      "Prediction: 0\n",
      "Actual: 0\n",
      "********************\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    row = test_set.iloc[i]\n",
    "    try:\n",
    "        pred = forest.predict(row['avg_vec'].reshape(1, -1))[0]\n",
    "    except:\n",
    "        continue\n",
    "    print(f\"Text: {row['text']}\")\n",
    "    print(f\"Prediction: {pred}\")\n",
    "    print(f\"Actual: {row['target']}\")\n",
    "    \n",
    "    print(\"*\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-midnight",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
